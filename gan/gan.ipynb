{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成對抗網路 GAN (Generative Adversarial Network )\n",
    "\n",
    "\n",
    "串接兩個類神經網路(NN)模型，一個負責生成以假亂真的資料(Generator)，另一個則負責辨別資料真偽(Discriminator)。兩個模型會互相對抗，最終目的為訓練出一個能夠產生高仿真資料的產生器。以下 GAN 都是以 MNIST 手寫辨識圖片作為訓練資料。\n",
    "\n",
    "# demo()\n",
    "展示出完成的訓練模型，並將所生成的圖片放入output資料夾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 201,217\n",
      "Trainable params: 201,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 455,952\n",
      "Trainable params: 454,928\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.658616, acc: 0.603516]  [A loss: 2.731130, acc: 0.000000]\n",
      "1: [D loss: 0.440978, acc: 0.808594]  [A loss: 2.034251, acc: 0.015625]\n",
      "2: [D loss: 0.371416, acc: 0.947266]  [A loss: 2.444614, acc: 0.000000]\n",
      "3: [D loss: 0.293098, acc: 0.943359]  [A loss: 2.033678, acc: 0.007812]\n",
      "4: [D loss: 0.274236, acc: 0.990234]  [A loss: 2.267777, acc: 0.000000]\n",
      "5: [D loss: 0.231809, acc: 0.990234]  [A loss: 2.146603, acc: 0.003906]\n",
      "6: [D loss: 0.220055, acc: 0.986328]  [A loss: 2.336306, acc: 0.000000]\n",
      "7: [D loss: 0.198077, acc: 0.994141]  [A loss: 2.331517, acc: 0.000000]\n",
      "8: [D loss: 0.172988, acc: 1.000000]  [A loss: 2.359945, acc: 0.000000]\n",
      "9: [D loss: 0.158649, acc: 1.000000]  [A loss: 2.397337, acc: 0.000000]\n",
      "10: [D loss: 0.149229, acc: 1.000000]  [A loss: 2.521745, acc: 0.000000]\n",
      "11: [D loss: 0.138933, acc: 1.000000]  [A loss: 2.508468, acc: 0.000000]\n",
      "12: [D loss: 0.130639, acc: 1.000000]  [A loss: 2.538407, acc: 0.000000]\n",
      "13: [D loss: 0.129898, acc: 1.000000]  [A loss: 2.637939, acc: 0.000000]\n",
      "14: [D loss: 0.112720, acc: 1.000000]  [A loss: 2.759001, acc: 0.000000]\n",
      "15: [D loss: 0.107013, acc: 1.000000]  [A loss: 2.695932, acc: 0.000000]\n",
      "16: [D loss: 0.105014, acc: 0.998047]  [A loss: 2.797055, acc: 0.000000]\n",
      "17: [D loss: 0.099477, acc: 1.000000]  [A loss: 2.811904, acc: 0.000000]\n",
      "18: [D loss: 0.095488, acc: 1.000000]  [A loss: 2.981514, acc: 0.000000]\n",
      "19: [D loss: 0.091572, acc: 1.000000]  [A loss: 2.853080, acc: 0.000000]\n",
      "20: [D loss: 0.085151, acc: 1.000000]  [A loss: 2.952469, acc: 0.000000]\n",
      "21: [D loss: 0.080795, acc: 1.000000]  [A loss: 3.070928, acc: 0.000000]\n",
      "22: [D loss: 0.080953, acc: 0.998047]  [A loss: 3.092739, acc: 0.000000]\n",
      "23: [D loss: 0.077779, acc: 1.000000]  [A loss: 3.127730, acc: 0.000000]\n",
      "24: [D loss: 0.075980, acc: 1.000000]  [A loss: 3.223589, acc: 0.000000]\n",
      "25: [D loss: 0.071010, acc: 1.000000]  [A loss: 3.219481, acc: 0.000000]\n",
      "26: [D loss: 0.068206, acc: 1.000000]  [A loss: 3.285152, acc: 0.000000]\n",
      "27: [D loss: 0.064541, acc: 1.000000]  [A loss: 3.314123, acc: 0.000000]\n",
      "28: [D loss: 0.064120, acc: 1.000000]  [A loss: 3.442486, acc: 0.000000]\n",
      "29: [D loss: 0.058462, acc: 1.000000]  [A loss: 3.451059, acc: 0.000000]\n",
      "30: [D loss: 0.054806, acc: 1.000000]  [A loss: 3.413326, acc: 0.000000]\n",
      "31: [D loss: 0.057239, acc: 1.000000]  [A loss: 3.523819, acc: 0.000000]\n",
      "32: [D loss: 0.054528, acc: 1.000000]  [A loss: 3.738266, acc: 0.000000]\n",
      "33: [D loss: 0.050204, acc: 1.000000]  [A loss: 3.616718, acc: 0.000000]\n",
      "34: [D loss: 0.051155, acc: 1.000000]  [A loss: 3.711727, acc: 0.000000]\n",
      "35: [D loss: 0.047438, acc: 1.000000]  [A loss: 3.689093, acc: 0.000000]\n",
      "36: [D loss: 0.045104, acc: 1.000000]  [A loss: 3.726506, acc: 0.000000]\n",
      "37: [D loss: 0.045128, acc: 1.000000]  [A loss: 3.855425, acc: 0.000000]\n",
      "38: [D loss: 0.046297, acc: 1.000000]  [A loss: 3.997595, acc: 0.000000]\n",
      "39: [D loss: 0.038575, acc: 1.000000]  [A loss: 3.895193, acc: 0.000000]\n",
      "40: [D loss: 0.041573, acc: 1.000000]  [A loss: 4.027445, acc: 0.000000]\n",
      "41: [D loss: 0.037584, acc: 1.000000]  [A loss: 3.964920, acc: 0.000000]\n",
      "42: [D loss: 0.036370, acc: 1.000000]  [A loss: 4.060280, acc: 0.000000]\n",
      "43: [D loss: 0.032381, acc: 1.000000]  [A loss: 4.114956, acc: 0.000000]\n",
      "44: [D loss: 0.031790, acc: 1.000000]  [A loss: 4.196472, acc: 0.000000]\n",
      "45: [D loss: 0.030928, acc: 1.000000]  [A loss: 4.222953, acc: 0.000000]\n",
      "46: [D loss: 0.031743, acc: 1.000000]  [A loss: 4.221089, acc: 0.000000]\n",
      "47: [D loss: 0.030757, acc: 1.000000]  [A loss: 4.347399, acc: 0.000000]\n",
      "48: [D loss: 0.029098, acc: 1.000000]  [A loss: 4.431085, acc: 0.000000]\n",
      "49: [D loss: 0.028213, acc: 1.000000]  [A loss: 4.477590, acc: 0.000000]\n",
      "50: [D loss: 0.027546, acc: 1.000000]  [A loss: 4.462689, acc: 0.000000]\n",
      "51: [D loss: 0.026190, acc: 1.000000]  [A loss: 4.508718, acc: 0.000000]\n",
      "52: [D loss: 0.027827, acc: 1.000000]  [A loss: 4.430139, acc: 0.000000]\n",
      "53: [D loss: 0.026876, acc: 1.000000]  [A loss: 4.629947, acc: 0.000000]\n",
      "54: [D loss: 0.025524, acc: 0.998047]  [A loss: 4.430581, acc: 0.000000]\n",
      "55: [D loss: 0.023603, acc: 1.000000]  [A loss: 4.776582, acc: 0.000000]\n",
      "56: [D loss: 0.020566, acc: 1.000000]  [A loss: 4.891505, acc: 0.000000]\n",
      "57: [D loss: 0.021208, acc: 1.000000]  [A loss: 4.726412, acc: 0.000000]\n",
      "58: [D loss: 0.020851, acc: 1.000000]  [A loss: 4.657680, acc: 0.000000]\n",
      "59: [D loss: 0.023077, acc: 1.000000]  [A loss: 4.859864, acc: 0.000000]\n",
      "60: [D loss: 0.019103, acc: 1.000000]  [A loss: 4.821685, acc: 0.000000]\n",
      "61: [D loss: 0.018184, acc: 1.000000]  [A loss: 4.886886, acc: 0.000000]\n",
      "62: [D loss: 0.018420, acc: 1.000000]  [A loss: 4.944081, acc: 0.000000]\n",
      "63: [D loss: 0.018202, acc: 1.000000]  [A loss: 4.899302, acc: 0.000000]\n",
      "64: [D loss: 0.017149, acc: 1.000000]  [A loss: 4.977122, acc: 0.000000]\n",
      "65: [D loss: 0.016896, acc: 1.000000]  [A loss: 4.922056, acc: 0.000000]\n",
      "66: [D loss: 0.015131, acc: 1.000000]  [A loss: 5.188990, acc: 0.000000]\n",
      "67: [D loss: 0.013401, acc: 1.000000]  [A loss: 5.222111, acc: 0.000000]\n",
      "68: [D loss: 0.015026, acc: 1.000000]  [A loss: 5.087080, acc: 0.000000]\n",
      "69: [D loss: 0.014853, acc: 1.000000]  [A loss: 5.339292, acc: 0.000000]\n",
      "70: [D loss: 0.014471, acc: 1.000000]  [A loss: 5.230136, acc: 0.000000]\n",
      "71: [D loss: 0.012900, acc: 1.000000]  [A loss: 5.266273, acc: 0.000000]\n",
      "72: [D loss: 0.012827, acc: 1.000000]  [A loss: 5.515723, acc: 0.000000]\n",
      "73: [D loss: 0.012546, acc: 1.000000]  [A loss: 5.272007, acc: 0.000000]\n",
      "74: [D loss: 0.011670, acc: 1.000000]  [A loss: 5.466077, acc: 0.000000]\n",
      "75: [D loss: 0.011885, acc: 1.000000]  [A loss: 5.464618, acc: 0.000000]\n",
      "76: [D loss: 0.012635, acc: 1.000000]  [A loss: 5.459918, acc: 0.000000]\n",
      "77: [D loss: 0.011950, acc: 1.000000]  [A loss: 5.573611, acc: 0.000000]\n",
      "78: [D loss: 0.011606, acc: 1.000000]  [A loss: 5.797702, acc: 0.000000]\n",
      "79: [D loss: 0.010033, acc: 1.000000]  [A loss: 5.643094, acc: 0.000000]\n",
      "80: [D loss: 0.008896, acc: 1.000000]  [A loss: 5.627220, acc: 0.000000]\n",
      "81: [D loss: 0.010992, acc: 1.000000]  [A loss: 5.643864, acc: 0.000000]\n",
      "82: [D loss: 0.009795, acc: 1.000000]  [A loss: 5.974606, acc: 0.000000]\n",
      "83: [D loss: 0.008059, acc: 1.000000]  [A loss: 5.866592, acc: 0.000000]\n",
      "84: [D loss: 0.008806, acc: 1.000000]  [A loss: 5.799500, acc: 0.000000]\n",
      "85: [D loss: 0.008283, acc: 1.000000]  [A loss: 5.793178, acc: 0.000000]\n",
      "86: [D loss: 0.009899, acc: 1.000000]  [A loss: 5.696201, acc: 0.000000]\n",
      "87: [D loss: 0.008717, acc: 1.000000]  [A loss: 5.950789, acc: 0.000000]\n",
      "88: [D loss: 0.007703, acc: 1.000000]  [A loss: 5.839353, acc: 0.000000]\n",
      "89: [D loss: 0.007945, acc: 1.000000]  [A loss: 6.045193, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90: [D loss: 0.006271, acc: 1.000000]  [A loss: 6.154541, acc: 0.000000]\n",
      "91: [D loss: 0.005861, acc: 1.000000]  [A loss: 6.110782, acc: 0.000000]\n",
      "92: [D loss: 0.007000, acc: 1.000000]  [A loss: 6.074967, acc: 0.000000]\n",
      "93: [D loss: 0.007313, acc: 1.000000]  [A loss: 6.053907, acc: 0.000000]\n",
      "94: [D loss: 0.006676, acc: 1.000000]  [A loss: 6.391842, acc: 0.000000]\n",
      "95: [D loss: 0.005074, acc: 1.000000]  [A loss: 6.178689, acc: 0.000000]\n",
      "96: [D loss: 0.005160, acc: 1.000000]  [A loss: 6.314347, acc: 0.000000]\n",
      "97: [D loss: 0.005971, acc: 1.000000]  [A loss: 6.284654, acc: 0.000000]\n",
      "98: [D loss: 0.006344, acc: 1.000000]  [A loss: 6.260091, acc: 0.000000]\n",
      "99: [D loss: 0.005662, acc: 1.000000]  [A loss: 6.477288, acc: 0.000000]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './gan_tutor_output/mnist_100.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f3e38b86c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprepared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#With 1000 steps, 2 Dense Discriminator, 2 Dense Generator, 100 Dim noise input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML-tutorial/gan/.prepared/gan.py\u001b[0m in \u001b[0;36mdemo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mmnist_dcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST_DCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElapsedTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mmnist_dcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mmnist_dcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML-tutorial/gan/.prepared/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_steps, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msave_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n\u001b[0;32m--> 147\u001b[0;31m                         noise=noise_input, step=(i+1))\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave2file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML-tutorial/gan/.prepared/gan.py\u001b[0m in \u001b[0;36mplot_images\u001b[0;34m(self, save2file, fake, samples, noise, step)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave2file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2253\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './gan_tutor_output/mnist_100.png'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.prepared')\n",
    "import gan as prepared\n",
    "\n",
    "prepared.demo()\n",
    "\n",
    "#With 1000 steps, 2 Dense Discriminator, 2 Dense Generator, 100 Dim noise input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models \n",
    "使用keras所提供的 Sequential model，此種model可以讓加入(.add)的層數(layer)按照加入的順序一一執行\n",
    "\n",
    "在NN練習中我們宣告為 nn_model = SimpleNN()，在這裡我們用類似的方式宣告model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Layer\n",
    "keras中所提供的Dense Layer就是神經網路最基礎、沒有變化的Layer，也和前面NN練習所用相同\n",
    "\n",
    "在Dense中也需要宣告Filter Number、Input長度或形狀以及Activation Function\n",
    "\n",
    "Dense(Filter Numer, input_shape=, activation=)\n",
    "\n",
    "由於D和G的input、output大小固定，增加中間的Layer數量來比較output image的差異\n",
    "\n",
    "將建好的D和G丟入.exe()執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "D = Sequential() #D as Discriminator\n",
    "\n",
    "#Using D.add(layer)\n",
    "\n",
    "D.add(Dense(256, input_shape=(784,), activation='relu')) \n",
    "# Fileter Number = 256 with relu activation\n",
    "# Input of D is a 28*28*1 2D picture and flattened into 28*28*1 = 784 1D row\n",
    "'''\n",
    "\n",
    "Add more layers with different filter numbers or activation to D here\n",
    "\n",
    "\n",
    "'''\n",
    "D.add(Dense(1, activation='sigmoid'))\n",
    "# Output of D is single value (represents true/fake image)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "G = Sequential() #G as Generator\n",
    "\n",
    "G.add(Dense(512, input_dim=100, activation='relu'))\n",
    "# Input of G is 100 1D noise\n",
    "'''\n",
    "\n",
    "Add more layers with different filter numbers or activation to G here\n",
    "\n",
    "\n",
    "'''\n",
    "G.add(Dense(784, activation='sigmoid'))\n",
    "#The noise will then be generated as 1D row with length 784 (represnets a fake image)\n",
    "\n",
    "\n",
    "gan.exe(D, G, 2000, 500) #.exe(D, G, stpes, save_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動手做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import sys\n",
    "sys.path.append('.prepared')\n",
    "import gan as prepared\n",
    "\n",
    "D = Sequential()\n",
    "D.add(Dense(256, input_shape=(784,), activation='relu'))\n",
    "D.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "G = Sequential()\n",
    "G.add(Dense(512, input_dim=100, activation='relu'))\n",
    "G.add(Dense(784, activation='sigmoid'))\n",
    "\n",
    "#prepared.exe(D, G, steps, save_interval)\n",
    "prepared.exe(D, G, 2000, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
