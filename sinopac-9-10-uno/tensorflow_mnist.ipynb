{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 簡易教學與實作\n",
    "\n",
    "## 1. 介紹\n",
    "\n",
    "Tensorflow 是由 Google 所發布的深度學習框架，讓使用者可以自行設計神經網路的架構，其優點在於在設計神經網路上非常靈活，使用者對於自己的神經路的運作可以有較全面的掌控，而缺點則是入門門檻相較於其他深度學習框架相對較高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 三種 Tensor\n",
    "\n",
    "tensor 在數學上的意思是任意維度的矩陣，對於深度學習有初步的認識後就不難想像**神經網路就是由許多的 Tensor 所組成**，而 Tensorflow 提供了三種不同特性的 tensor 供使用者建構自己的神經網路\n",
    "\n",
    "在介紹之前，先定義兩個名詞：\n",
    "\n",
    "- tensor：任意維度的矩陣\n",
    "- shape：tensor 在每一維度上的大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 tf.constant()\n",
    "\n",
    "第一個 tensor 是 tf.constant() 所產生的 tensor，其他的特性為**一旦產生了以後便不能修改它的值**，用法可以參考以下程式碼："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 使用 tf.constant() 產生 Tensor\n",
    "a = tf.constant(0)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼產生了一個 tensor 被命名為 a 且其值為 0\n",
    "\n",
    "\n",
    "接著如果想要產生內含矩陣的 tensor 可以這麼做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"Const_2:0\", shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 產生內容為 1 維矩陣的 Tensor\n",
    "b = tf.constant([1, 2, 3])\n",
    "print(b)\n",
    "\n",
    "# 產生內容為 2 維矩陣的 Tensor\n",
    "c = tf.constant([[2, 4], [6, 8], [10, 12]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼產生了一個 1 維 tensor 一個 2 維 tensor，其中各自內容為：\n",
    "\n",
    "$\n",
    "b = \n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "c = \n",
    "\\begin{bmatrix}\n",
    "    2 & 4 \\\\\n",
    "    6 & 8 \\\\\n",
    "    10 & 12\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 tf.Variable()\n",
    "\n",
    "tf.Variable() 的用法跟 tf.constant() 類似，它們之間的差在於 **tf.Variable() 產生出來的 tensor 其值可以被修改**，基本用法如下，與 tf.constant() 一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(3,) dtype=int32_ref>\n",
      "<tf.Variable 'Variable_2:0' shape=(3, 2) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0)\n",
    "b = tf.Variable([1, 2, 3])\n",
    "c = tf.Variable([[2, 4], [6, 8], [10, 12]])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "還有一些比較進階的用法，也是比較常用的用法，也就是將 tensor 裡面的值隨機指定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=(3, 2) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "d = tf.Variable(tf.random_uniform(shape = (3, 2)))\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 tf.placeholder()\n",
    "\n",
    "這個 tensor 比較特殊，它的用法是**先產生 tensor 但是不給值，之後再給**，用法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32, shape = (3, 2))\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如此產生了一個 shape 為 (3, 2) 但是還沒有任何數字的 tensor，甚至可以產生連 shape 的某幾維都不明確的 tensor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.placeholder(tf.float32, shape = (None, 2))\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這代表這個 tensor 之後可以放入 shape 為 (n, 2) 的矩陣，這裡 n 可以是大於 0 的任意正整數，至於如何給值會在下一個小節探討"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 獲取 tensor 的值\n",
    "\n",
    "前一節介紹了三種 tensor，可以注意到 tensor 的值沒辦法透過 print() 來查看，那是因為 Tensorflow 有提供自己的一套方法來讓使用者獲取 tensor 的值\n",
    "\n",
    "### 3.1 tf.Session()\n",
    "\n",
    "在 Tensorflow 中必須使用 tf.Session() 來獲得 tensor 的內容，具體用法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1 2 3]\n",
      "[[ 2  4]\n",
      " [ 6  8]\n",
      " [10 12]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(0)\n",
    "b = tf.constant([1, 2, 3])\n",
    "c = tf.constant([[2, 4], [6, 8], [10, 12]])\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "a_value = sess.run(a)\n",
    "b_value = sess.run(b)\n",
    "c_value = sess.run(c)\n",
    "\n",
    "print(a_value)\n",
    "print(b_value)\n",
    "print(c_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面程式碼可以看到，先用 tf.Session() 產生 sess，接著再用 sess.run() 來產生 tensor 的值\n",
    "\n",
    "接著是察看 tf.Variable() 的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[ 0.95073557  0.71619725]\n",
      " [ 0.30778825  0.95408607]\n",
      " [ 0.9181844   0.03299463]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([1, 2, 3])\n",
    "b = tf.Variable(tf.random_uniform(shape = (3, 2)))\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 非常重要 !\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "a_value = sess.run(a)\n",
    "b_value = sess.run(b)\n",
    "\n",
    "print(a_value)\n",
    "print(b_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable() 的察看方法和 tf.constant() 差不多，但是它多了一行 `sess.run(tf.global_variables_initializer())`，如果少了這一行的話程式會發生錯誤，可以注意到由於 b 是使用隨機附值的方式，所以印出來的數值為亂數\n",
    "\n",
    "接著是察看 tf.placeholder() 的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[5 6]\n",
      " [7 8]]\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.int32, shape = (2, 2))\n",
    "b = tf.placeholder(tf.int32, shape = (None, 2))\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "a_value_1 = sess.run(a, feed_dict = {a: [[1,2],[3,4]]})\n",
    "a_value_2 = sess.run(a, feed_dict = {a: [[5,6],[7,8]]})\n",
    "\n",
    "# shape = (2, 2)\n",
    "b_value_1 = sess.run(b, feed_dict = {b: [[1,2],[3,4]]})\n",
    "\n",
    "# shape = (3, 2)\n",
    "b_value_2 = sess.run(b, feed_dict = {b: [[5,6],[7,8], [9, 10]]})\n",
    "\n",
    "print(a_value_1)\n",
    "print(a_value_2)\n",
    "\n",
    "print(b_value_1)\n",
    "print(b_value_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從上面程式碼可以到，透過在 sess.run() 中加入 feed_dict 的參數來給 tf.placeholder() 數值，同時也可以注意一下由於 b 一開始 shape 為 (None, 2) 所以可以給它 shape 為 (2, 2) 或 (3, 2) 的矩陣"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 矩陣運算\n",
    "\n",
    "### 4.1 線性計算\n",
    "\n",
    "對於深度學習有初步認識的話，可以知道神經網路每層在經過激活 (activate) 之前會有一個矩陣運算：\n",
    "\n",
    "$Output = X \\times Weight + Bias$\n",
    "\n",
    "這條數學式中用到了矩陣乘法跟矩陣加法，而 Tensorflow 中可以使用 tf.matmul() 做矩陣乘法，矩陣加法則可以用 + 來做，具體程式碼如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23 -26]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([[1, 2, 3]])\n",
    "Weight = tf.Variable([[1, -2], [3, -4], [5, -6]])\n",
    "Bias = tf.Variable([1, 2])\n",
    "\n",
    "Output = tf.matmul(X, Weight) + Bias\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(sess.run(Output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼可以用數學表示如下：\n",
    "\n",
    "$\n",
    "Output = \n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 3\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "    1 & -2 \\\\\n",
    "    3 & -4 \\\\\n",
    "    5 & -6\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "    1 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "而計算出來的結果就是 [23, -26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 激活函數\n",
    "\n",
    "神經網路每層線性計算後會經過激活的階段，Tensorflow 也有提供對應的方法來直接計算激活後的結果，將上一小節程式碼加入激活函數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23.   0.]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([[1, 2, 3]], dtype = tf.float32)\n",
    "Weight = tf.Variable([[1, -2], [3, -4], [5, -6]], dtype = tf.float32)\n",
    "Bias = tf.Variable([1, 2], dtype = tf.float32)\n",
    "\n",
    "Output = tf.matmul(X, Weight) + Bias\n",
    "\n",
    "# 使用 Relu 激活函數\n",
    "Activate = tf.nn.relu(Output)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(sess.run(Activate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程式碼使用了 tf.nn.relu() 來做為激活函數，而 relu 會將所有小於 0 的值自動設為 0，大於 0 的值則不變，所以輸出結果從 [23, -26] 變成 [23, 0]，除了 relu 以外還有兩個常見的激活函數，可以試著替換 tf.nn.relu() 並觀察輸出：\n",
    "\n",
    "- Sigmoid：tf.nn.sigmoid()\n",
    "- Tanh：tf.nn.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
