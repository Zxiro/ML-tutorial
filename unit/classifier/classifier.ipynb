{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your classifier\n",
    "\n",
    "## 1. Data preprocessing\n",
    "\n",
    "We demonstrate common preprocessing technique with two example.\n",
    "* Normalization in cat classifier\n",
    "* Categorical data convertion and missing value in Pokémon classifier\n",
    "\n",
    "### (1 - A) Normalization\n",
    "\n",
    "Reference to Andrew Ng's course on coursera.\n",
    "The cat image dataset contains pictures of cat and other stuff. In our [cat classifier](#cat_classifier) example each X represent a single 64 * 64 * 3  RGB image, and the label of each image is decribed as follow.\n",
    "- 0 : non-cat\n",
    "- 1 : cat\n",
    "\n",
    "We divide each pixel by 255, and this operation is called normalization. After dividing the image by 255, the original value of color will be rescaled to 0~1. By normalizing the data, the optimization algorithms will be able to find the optimal more efficiently. Each feature matters equally.\n",
    "\n",
    "In this example, we already know the distribution of each pixel is ranging from 0 to 255. That's why the magic number is 255. However, in general cases you wouldn't know the distribution of each feature. Our common solution is to use [min max normalization](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).\n",
    "\n",
    "### (1 - B) Categorical data convertion\n",
    "\n",
    "Normally, there will be a lot of features that won't be discribed in numerical data such as color and type in our Pokémon dataset.\n",
    "\n",
    "| **Ordinal Values** | **Nominal Values** |\n",
    "|--------------------|--------------------|\n",
    "| Generation | Color, Type|\n",
    "\n",
    "Instead, they probably are interpreted with categorical data. We introduce two different approaches to convert from categorical data to numical data. Take two features, **Color** and **Type_1** for example.\n",
    "\n",
    "1. **Color**:\n",
    "    * The method we demonstrate here is one-hot encoding, which transform the categorical features to combinations of 0s and 1s. Using numeric features (0:red, 1:blue ....) to represent category will confuse the classifier since the **incremental** figures do not map to their representative colors.\n",
    "  \n",
    "2. **Type_1**:\n",
    "    * Assume the relation between types is so simple that we can view it as the itensity of the Pokémon.\n",
    "    * We didn't transform Type_1 as one-hot due to the fact that Type_1 would be used as label. The classifier we presented in this example is SVM, and SVM takes 0, 1, 2, 3... as different categories. As a result we only transform the string categories to numbers.\n",
    "    * Here, we merged similar types into the same categories as presented below.\n",
    "    \n",
    "|  Type_1  |  catogory  |\n",
    "|--------|---------|\n",
    "|Grass|1|\n",
    "|Fire|2|\n",
    "|Water+Ice|3|\n",
    "|Bug|4|\n",
    "|Normal|5|\n",
    "|Poison + Ghost + Dark|6|\n",
    "|Electric|7|\n",
    "|Ground + Rock|8|\n",
    "|Flying + Fairy + Dragon|9|\n",
    "|Fighting + Psychic + Steel|10|\n",
    "\n",
    "### (1 - C) missing value\n",
    "\n",
    "Another even more often case is the value in data doesn't exist so called \"**missing value**\". There are many methods to deal with missing value such as dorpping the feature/sample, or giving values by zero/column or mean/interpolation. The substitute for missing value depends upon your domain knowledge or experiences.\n",
    "\n",
    "note: \n",
    "1. The Pokémon dataset can be downloaded [here](https://www.kaggle.com/alopez247/pokemon).\n",
    "2. The [Pokémon classifier](#pokemon) takes features other than \"type_1\" as input to predict corresponding type_1.\n",
    "\n",
    "## 2. Use machine learning tool to build model\n",
    "\n",
    "1. [sklearn](http://scikit-learn.org/stable/)\n",
    "    One can use convenient function in sklearn instead of implement every classifier yourself including both supervised and unsupervised learning algorithms. We will use it to build classifiers in our following examples.\n",
    "\n",
    "2. [pandas](https://pandas.pydata.org/)\n",
    "    Pandas provide also a lot of API for you to process data in high level. Compared with sklearn, pandas focus on making data preprocessing simple and clean. Try to apply it in your stock model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cat_classifier'>cat classifier</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_X = np.load('train_X.npy')\n",
    "train_Y = np.load('train_Y.npy')\n",
    "test_X = np.load('test_X.npy')\n",
    "test_Y = np.load('test_Y.npy')\n",
    "plt.imshow(train_X[7]) # input a RGB 64 * 64 image\n",
    "\n",
    "# flatten the input image\n",
    "num_train = train_X.shape[0]\n",
    "num_test = test_X.shape[0]\n",
    "flatten_train_X = train_X.reshape(num_train,-1)\n",
    "flatten_test_X = test_X.reshape(num_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each pixel by dividing 255\n",
    "norm_train_X = flatten_train_X / 255\n",
    "norm_test_X = flatten_test_X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(norm_train_X, train_Y)\n",
    "\n",
    "# demo the classifier really working\n",
    "print(\"Model prediction: {}\".format(clf.predict(norm_test_X[25].reshape(1,-1))))\n",
    "plt.imshow(test_X[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pokemon'>pokemon classifier</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pokemon_alopez247.csv')\n",
    "df.head(5) # before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dictionary = {\"Type_1\":{ 'Grass': 1, 'Fire': 2, 'Water': 3, 'Bug': 4, 'Normal': 5, 'Poison': 6, 'Electric': 7, 'Ground': 8, 'Fairy': 9, \n",
    " 'Fighting': 10, 'Psychic': 10, 'Rock': 8, 'Ghost': 6, 'Ice': 3, 'Dragon': 9, 'Dark':6, 'Steel': 10, 'Flying': 9}}\n",
    "df = df.replace(mapping_dictionary) # 透過 replace function 可以方便地把字串改為對應的數字\n",
    "df[\"isLegendary\"] = df[\"isLegendary\"].astype(int) # Boolean to int\n",
    "df[\"hasMegaEvolution\"] = df[\"hasMegaEvolution\"].astype(int)\n",
    "\n",
    "dummy_df = pd.get_dummies(df['Color'])  ## one-hot encoding\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df = df.drop('Color', axis=1)\n",
    "df = df.drop(['Number','Name', 'Type_2', 'Egg_Group_1', 'Egg_Group_2', 'hasGender', 'Body_Style'],axis=1)\n",
    "df.head(5) # after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deal with missing value\n",
    "print(df.isnull().sum()) # Pr_Male has 77 missing value\n",
    "df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can draw histgram with pandas\n",
    "df[['HP', 'Attack']].plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_arrays(df):\n",
    "    X = np.array(df.iloc[:,1:])\n",
    "    y = np.array(df['Type_1'])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = get_arrays(df_train)\n",
    "test_X, test_Y = get_arrays(df_test)\n",
    "scaler = StandardScaler()\n",
    "svc = SVC(C=5, gamma=0.04)\n",
    "clf = Pipeline([('scaler', scaler), ('svc', svc)])\n",
    "clf.fit(train_X, train_Y)\n",
    "print(\"Accuracy: {}\".format(clf.score(train_X, train_Y)))\n",
    "print(\"Accuracy: {}\".format(clf.score(test_X, test_Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "\n",
    "\n",
    " * 本次作業為建構[UCI German Credit Data](https://onlinecourses.science.psu.edu/stat857/node/215) 分類模型  \n",
    " * 該資料集包含 1000 筆貸款資料，其中 700 筆正樣本(credit-worthy)以及 300 筆負樣本(not credit-worthy)。每個樣本有 20 個特徵，其中 17 個類別(categorical)特徵，3 個為數值(numeric)特徵，請參考[特徵的細節](https://onlinecourses.science.psu.edu/stat857/node/222)。\n",
    " * 利用準備好的工具，建構分類模型，請參考 [Classifier comparison](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) 選擇機器學習分類器。\n",
    " * 以下為助教提供的資料集介紹及分類器示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared 為助教預先準備的示範程式\n",
    "import sys\n",
    "sys.path.append('.prepared')\n",
    "import classification as prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料集\n",
    "\n",
    "UCI German Credit Data 包含 800 筆訓練資料與 200 筆測試資料。每筆由一個 20 維的特徵向量與一個 `1` 或 `0` 的類別組成。其中 `1` 代表正樣本(credit-worthy)；`0` 代表負樣本(not credit-worthy)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prepared.x_train.shape) # 800 筆訓練資料的特徵\n",
    "print(prepared.x_train[:3])   # 印出前三筆訓練資料的特徵\n",
    "print()\n",
    "print(prepared.y_train.shape) # 800 筆訓練資料的類別\n",
    "print(prepared.y_train[:3])   # 印出前三筆訓練資料的類別\n",
    "print()\n",
    "print(prepared.x_test.shape)  # 200 筆訓練資料的特徵\n",
    "print(prepared.y_test.shape)  # 200 筆訓練資料的類別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示範分類器\n",
    "\n",
    "使用訓練資料(`x_train` 與 `y_train`)訓練示範分類器(`demo_clf`)，在訓練資料與測試資料(`x_test` 與 `y_test`)上評估其正確率。請修改下方[動手做](#動手做)的程式碼試著超越這個示範分類器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用訓練資料訓練示範分類器, `demo_clf`\n",
    "demo_clf = prepared.demo(prepared.x_train, prepared.y_train)\n",
    "\n",
    "# 在訓練資料與測試資料上評估其正確率\n",
    "prepared.evaluate(demo_clf, prepared.x_train, prepared.x_test, prepared.y_train, prepared.y_test)\n",
    "\n",
    "if 'DecisionTreeClassifier' == type(clf).__name__: # if `clf` is a decision tree\n",
    "    prepared.plot(clf) # plot the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意 \n",
    "## 本週作業除了以下建置分類器外，還要提交結果於股票系統，股票介紹請見 stock資料夾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動手做\n",
    "\n",
    "修改以下程式碼，試著使用不同的機器學習演算法，建構比示範分類器更好的模型。換句話說，在測試資料上的正確率超過 `0.765`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import classifiers you want to use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO: try different classifiers\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "clf = clf.fit(prepared.x_train, prepared.y_train) # train `clf`\n",
    "prepared.evaluate(clf, prepared.x_train, prepared.x_test, prepared.y_train, prepared.y_test) # evaluate `clf`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference to  Andrew Ng, Professor Lin 's course on coursera and Professor Wu in NTHU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
