{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "###### tags: `mlb`\n",
    "\n",
    "## 1. Convolution Operation\n",
    "\n",
    "### 1.1 Motivation\n",
    "\n",
    "Disadvantage of neural network on image classification :\n",
    "\n",
    "1. Too many trainable variables.\n",
    "2. Too much redundant computation.\n",
    "\n",
    "In disadvantage 1, we can consider a neural network as follows : \n",
    "\n",
    "![](figure/nn_on_img_classification.svg)\n",
    "\n",
    "Total number of trainable variables is $120000 \\times 5000 + 5000 + 5000 \\times 10 + 10 = 600,055,010$\n",
    "\n",
    "In disadvantage 2, see the following figure : \n",
    "\n",
    "![](figure/nn_profiling.svg)\n",
    "\n",
    "Dot line means that it may not be an important information for the next neuron.\n",
    "\n",
    "And too much redundant information (noise) will influence neural network to extract feature.\n",
    "\n",
    "### 1.2 Feature Extraction\n",
    "\n",
    "#### 1.2.1 Local Features\n",
    "\n",
    "Idea : how about extracting features from local region in a image ?\n",
    "\n",
    "1. Maybe we can use some methods to find local features in a image.\n",
    "2. And we can merge some local features into a  high-level feature. \n",
    "3. Finally, we can use these high-level features to do classification.\n",
    "\n",
    "![](figure/feature_in_local.svg)\n",
    "\n",
    "#### 1.2.2 Filter\n",
    "\n",
    "But how do we extract local features ?\n",
    "\n",
    "We can use many **filters** to search local features in a image.\n",
    "\n",
    "Filter : a matrix (2D or 3D) which represents a specific pattern.\n",
    "\n",
    "![](figure/filter_prototype.svg)\n",
    "\n",
    "We can performe dot product operation between a filter and a local region of a image.\n",
    "- If the result of dot product operation exceeds a threshold, we will expect that it is a valid local feature. (Remember **bias** ?)\n",
    "\n",
    "![](figure/2D_Filter.svg)\n",
    "\n",
    "The filter will perfomre the above operations to every local region of the image.\n",
    "- We will get a output matrix after the operation.\n",
    "- The output matrix is called **feature map**.\n",
    "\n",
    "![](https://i.imgur.com/pKEveTw.png)\n",
    "![](https://i.imgur.com/t2ahvHN.png)\n",
    "\n",
    "And next, we can use the same filter methods to extract even more higher level features from those feature maps.\n",
    "\n",
    "![](https://i.imgur.com/vzYgFd6.png)\n",
    "\n",
    "\n",
    ":::info\n",
    "Note:\n",
    "In practice, a filter is a 3D matrix. \n",
    "- Images are 3D matrix (RGB channels).\n",
    "- Feature maps will be concatenated on channel-wise direction.\n",
    ":::\n",
    "\n",
    "### 1.3 Convolution\n",
    "\n",
    "Filter : a $H \\times W \\times C$ matrix ($H$ = filter height, $W$ = filter width, $C$ = number of channel)\n",
    "- In practice, we will let $H = W$ in a 2D convolution layer.\n",
    "- $H$, $W$ are always odd numbers. \n",
    "    - [Why convolutions always use odd-numbers as filter_size\n",
    "](https://datascience.stackexchange.com/questions/23183/why-convolutions-always-use-odd-numbers-as-filter-size)\n",
    "\n",
    "Convolution layer : a layer contains many filters.\n",
    "- We can use a $N \\times H \\times W \\times C$ matrix to represent all filters in a convolution layer ($N$ = number of filters)\n",
    "\n",
    "Filters will used on images (or input data) to generate feature maps.\n",
    "- Convolution layer will generate feature maps by all filters in this layer.\n",
    "\n",
    "\n",
    "We can use an equation to represent a convolution layer : \n",
    "\n",
    "$$\n",
    "Output = Activation(Convolution(Input, Filters) + Bias)\n",
    "$$\n",
    "\n",
    "- $Convolution(.)$ works as the following figure : \n",
    "\n",
    "![](https://i.imgur.com/VaPC8z7.png)\n",
    "\n",
    "- A feature map will add a bias value. So, $Bias$ here is a vector with $C$ dimension.\n",
    "- Assume $Input$ is a $I \\times J \\times C$ matrix, where $I$ = height, $J$ = width.\n",
    "    - We can expect $Output$ is a $(I - H + 1) \\times (J - W + 1) \\times N$ matrix.\n",
    "\n",
    "After a convolution layer, we can send the output data to the next convolution layer.\n",
    "\n",
    "How do we define filters in a convolution layer ?\n",
    "- We random initialize all filters and bias. And we treat them as trainable variables.\n",
    "    - Optimize with backpropagation.\n",
    "\n",
    "Now, we can compute the number of trainable variables in a convolution layer : \n",
    "\n",
    "- Assume $H = W = 3$, $C = 3$, $N = 64$, we can get the number of trainable variables is $3 \\times 3 \\times 3 \\times 64 + 64 = 1792$\n",
    "- You can find that the number of parameters depends on your definition of a convolution layer. And it is independent of input data.\n",
    "\n",
    "### 1.4 Stride\n",
    "\n",
    "Until now, we have at least 3 hyperparameters : $N$, $H$, $W$\n",
    "- **Notice** : $C$ is not a hyperparameter. $C$ should be set according to the number of channels of input data.\n",
    "\n",
    "Now, we will focus on the sliding step of filters : \n",
    "\n",
    "\n",
    "If we slide a step once time : \n",
    "- we will get a $(I - H + 1) \\times (J - W + 1) \\times N$ output matrix.\n",
    "\n",
    "If we slide two steps once time : \n",
    "- we will get a $[(I - H + 1) / 2] \\times [(J - W + 1)/2] \\times N$ output matrix.\n",
    "\n",
    "If we slide $S$ steps once time : \n",
    "- we will get a $[(I - H + 1)/S] \\times [(J - W + 1)/S] \\times N$ output matrix.\n",
    "\n",
    "![](https://i.imgur.com/fiRqZpT.png)\n",
    "\n",
    "We define **stride** as the step size of every slide.\n",
    "\n",
    "We can use stride to control the dimension of the output matrix.\n",
    "\n",
    "### 1.5 Zero-padding\n",
    "\n",
    "You will find it a little hard to compute the dimension of the output matrix of a convolution layer.\n",
    "\n",
    "So, we can add 0 to input data to avoid dimension reduction.\n",
    "\n",
    "![](https://i.imgur.com/4PMrKqp.png)\n",
    "\n",
    "Let's consider the condition that stride is 1. Padding 0 can keep dimension (height, width) of the output matrix same as input matrix.\n",
    "\n",
    "And then, we consider the condition that stride > 1. We can pad 0 to let the dimension of output matrix is $ceil(I/S) \\times ceil(J/S) \\times N$ \n",
    "\n",
    "\n",
    "Advantage of zero-padding : \n",
    "\n",
    "1. Easier to design networks.\n",
    "2. Allows us to design deeper networks.\n",
    "3. Padding actually improves performance by keeping borders information.\n",
    "\n",
    "## 2. Pooling Operation\n",
    "\n",
    "### 2.1 Pooling\n",
    "\n",
    "Motivation : \n",
    "\n",
    "1. Human can recognize object in a low-resolution image.\n",
    "    - If a 500 x 500 image is compressed to a 250 x 250 image, we can still recognize the objects in the image.\n",
    "2. Some value in feature maps may be redundant or noisy.\n",
    "3. Computing high-dimension feature maps needs larger software and hardware cost.\n",
    "\n",
    "Idea : we can convert every $P \\times P$ region on a feature map to a single value. The following figure show the condition if $P = 2$.\n",
    "\n",
    "![](https://i.imgur.com/NUFx4tM.png)\n",
    "\n",
    "Two ways to generate the value from a $P \\times P$ matrix : \n",
    "1. Average pooling: the value is the average of matrix elements\n",
    "2. Max pooling : the value is the maximum element in the matrix.\n",
    "    - Max pooling is the most common pooling operation in convolutional neural networks.\n",
    "\n",
    "Pooling layer : a layer perform pooling operation\n",
    "- There is no trainable variable here.\n",
    "- There is no activation function, too.\n",
    "- Pooling operation will perform at each feature map. Feature maps are indenpendent of each other.\n",
    "\n",
    "### 2.2 Stride\n",
    "\n",
    "In section 1, we know that stride will affect the dimension of output matrix. So, if we want to reduce dimension of the output of a pooling layer, we should let stride > 1.\n",
    "- In common, we will set stride to 2.\n",
    "\n",
    "We can expect the dimension of the output matrix to be $[H/S] \\times [W/S] \\times N$.\n",
    "- Dimension of output matrix is indenependent of $P$.\n",
    "\n",
    "### 2.3 Zero-padding\n",
    "\n",
    "We can pad 0 before a pooling operation.\n",
    "\n",
    "- Dimension of the output matrix after the pooling layer will be $ceil(H/S) \\times ceil(W/S) \\times N$.\n",
    "\n",
    "## 3. Convolutional Neural Networks\n",
    "\n",
    "### 3.1 Basic Architecture\n",
    "\n",
    "![](https://i.imgur.com/rb7nSq1.png)\n",
    "\n",
    "Feel free to arrange your convolution layers and pooling layers.\n",
    "\n",
    "Flatten : reshape feature maps to a 1D vector.\n",
    "- For example, a 3D feature maps matrix shaped ($50 \\times 50 \\times 16$) will be reshaped to a vector with length $50 \\times 50 \\times 16 = 40000$.\n",
    "\n",
    "Visualize filters : \n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*Ji5QhY9QXBlpNNLH4qAcNA.png)\n",
    "\n",
    "### 3.2 1D Convolutional Neural Networks\n",
    "\n",
    "Convolutional neural networks is not limited to 2D image data.\n",
    "- It can be applied to any features with **local** patterns.\n",
    "\n",
    "For example : \n",
    "\n",
    "1. Text\n",
    "2. Voice\n",
    "3. Protein sequence\n",
    "4. DNA sequence\n",
    "5. 3D spatial data\n",
    "\n",
    "Here, we will focus on 1D sequence features.\n",
    "\n",
    "1D convolutional neural networks are similar to 2D convolutional neural networks. But convolution and pooling operation in 1D neural network has only one sliding direction.\n",
    "\n",
    "\n",
    "The following figure represent a 1D convolution operation : \n",
    "![](https://i.imgur.com/4MaP97V.png)\n",
    "\n",
    "The following figure represent a 1D pooling operation : \n",
    "![](https://i.imgur.com/hGBcG4O.png)\n",
    "\n",
    ":::info\n",
    "Hint : \n",
    "The size of a filter depends on the size of the local pattern.\n",
    ":::\n",
    "\n",
    "## 4. Evolution of Convolutional Neural Networks\n",
    "\n",
    "In this section, we will discuss some famous convolutional neural networks architecture : \n",
    "\n",
    "- The first convolutional neural network\n",
    "- Champions of ILSVRC (ImageNet Large Scale Visual Recognition Competition) every years\n",
    "- Some improvement of convolutional neural networks\n",
    "\n",
    "We only introduce the basic conception of those neural networks. For more detail, please take a look for their papers.\n",
    "\n",
    "### 4.1 LeNet\n",
    "\n",
    "Paper : [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n",
    "\n",
    "![](https://i.imgur.com/YJL8Z2M.png)\n",
    "\n",
    "- It is the first convolutional neural network.\n",
    "- Total number of layers : 7\n",
    "- Subsampling layer is neither max pooling nor average pooling.\n",
    "    - $Sigmoid(Sum(x_{00}, x_{01}, x_{10}, x_{11}) \\times w + b)$ \n",
    "- Gaussian connection is its output layer used to classify.\n",
    "    - $y_i = \\sum_{j} (x_j - w_{ij}) ^ 2$\n",
    "- Loss function : MSE (mean sqare error) + MLE (maximum likelihood estimation)\n",
    "    - $E(W) =\\frac{1}{P} \\sum_{p=1}^{P} (y_{Dp} (Z_p, W) + log(e^{-j} + \\sum_i e^{-y_i(Z_p, W)}))$\n",
    "\n",
    "### 4.2 AlexNet\n",
    "\n",
    "Paper : [ImageNet Classification with Deep ConvolutionalNeural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "\n",
    "![](https://i.imgur.com/DcrhnHl.png)\n",
    "\n",
    "- Champion of ILSVRC 2012\n",
    "- Train on two GPUs\n",
    "- Use ReLU as its activation function\n",
    "- Local response normalization : \n",
    "\n",
    "$$\n",
    "b_{x,y}^i = a_{x,y}^i / (k + \\alpha\\sum_{j=max(0, i-n/2)}^{min(N-1, i+n/2)} (a_{x,y}^i)^2)^\\beta\n",
    "$$\n",
    "\n",
    "- Overlapping pooling : $P = 3, S = 2$\n",
    "- Dropout in the first two fully connected layers.\n",
    "\n",
    "### 4.3 VGG\n",
    "\n",
    "Paper : [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "\n",
    "![](https://i.imgur.com/kzHiggO.png)\n",
    "\n",
    "\n",
    "- Contribution : deeper convolutional neural networks have better performance.\n",
    "- Very small filters : $3 \\times 3$\n",
    "- VGG-11, VGG-13, VGG-16, VGG-19 : 11, 16, 13, 19 mean the number of layers.\n",
    "\n",
    "### 4.4 Network in Network\n",
    "\n",
    "Paper : [Network In Network](https://arxiv.org/pdf/1312.4400.pdf)\n",
    "\n",
    "![](https://i.imgur.com/cUJpBYr.png)\n",
    "\n",
    "#### 4.4.1 MLP convolution layer\n",
    "\n",
    "![](https://i.imgur.com/wH1cnqW.png)\n",
    "\n",
    "Motivation : \n",
    "- Increase non-linear complexity between two convolution layers\n",
    "- Reduce trainable variables\n",
    "\n",
    "We can use convolution layer with $1 \\times 1$ filters as MLP.\n",
    "Why it reduces trainable variables ? Consider the following two architectures : \n",
    "- conv 3x3(input=64 channels, output=128 channels) : $3 \\times 3 \\times 64 \\times 128 = 73728$\n",
    "- conv 3x3(input=64 channels, output=32 channels) -> conv 1x1 (input=32 channels, output=128 channels) : $3 \\times 3 \\times 64 \\times 32 + 1 \\times 1 \\times 32 \\times 128= 22528$\n",
    "\n",
    "#### 4.4.2 Global average pooling\n",
    "\n",
    "Motivation : \n",
    "- Fully connected layers have too many parameters (trainable variables).\n",
    "    - It causes overfitting easily.\n",
    "    - For example, 85% parameters ($\\cong 123,000,000$) come from fully connected layers in VGG-19.\n",
    "\n",
    "We can find that **flatten** keep too many values. And thus the coming fully-connected will need to use a lot of paramenters.\n",
    "\n",
    "Idea : replace flatten with global average pooling\n",
    "- Convert a feature map to a single value.\n",
    "- Max pooling will loss too much information.\n",
    "\n",
    "![](https://i.imgur.com/e1bhxuD.png)\n",
    "\n",
    "Advantage : \n",
    "- Reduce parameters\n",
    "- Regularization\n",
    "\n",
    "### 4.5 GoogLeNet\n",
    "\n",
    "Paper : [Going deeper with convolutions](https://arxiv.org/pdf/1409.4842.pdf)\n",
    "\n",
    "![](https://i.imgur.com/jZtn0Fh.png)\n",
    "\n",
    "- Champion of ILSVRC 2014\n",
    "- Reference network in network\n",
    "    - Use convolution layer with $1 \\times 1$ filters and global average pooling.\n",
    "- Total number of layers is 23 but 12 times smaller than AlexNet.\n",
    "\n",
    "- Inception module : \n",
    "    - How to concatenate feature maps after convolution layer and pooling layer ?\n",
    "        - Zero-padding\n",
    "        - Stride in pooling layers is **1**.\n",
    "\n",
    "![](https://i.imgur.com/Rj1SQIz.png)\n",
    "\n",
    "- Inception v3, v4 : \n",
    "    - [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/pdf/1512.00567.pdf)\n",
    "    - [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/pdf/1602.07261.pdf)\n",
    "\n",
    "### 4.6 ResNet\n",
    "\n",
    "Paper : [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "\n",
    "![](https://i.imgur.com/KtCM7pX.png)\n",
    "\n",
    "- Champion of ILSVRC 2015\n",
    "- Residual block : skip connection can avoid gradient vanish.\n",
    "\n",
    "![](https://i.imgur.com/OsTbelV.png)\n",
    "\n",
    "- It is possible to train a convolutional neural network with more than 1000 layers.\n",
    "\n",
    "- Variants : \n",
    "    - DenseNet\n",
    "    - Inception-ResNet\n",
    "\n",
    "- Analysis performance in different residual block architecture : [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf)\n",
    "\n",
    "### 4.7 SENet\n",
    "\n",
    "Paper : [Squeeze-and-Excitation Networks](https://arxiv.org/pdf/1709.01507.pdf)\n",
    "\n",
    "![](https://i.imgur.com/LLCQVzZ.png)\n",
    "\n",
    "- Champion of ILSVRC 2017\n",
    "- Idea : if a network can be enhanced from the aspect of channel relationship ?\n",
    "    - Let model learn the importance of each channel automatically.\n",
    "- Squeeze-and-Excitation block : \n",
    "    - SE-Inception module : \n",
    "![](https://i.imgur.com/liiWXTV.png)\n",
    "    - SE-ResNet module : \n",
    "![](https://i.imgur.com/2Wr2Zb9.png)\n",
    "\n",
    "- $<10 \\%$ additional parameters, computation cost, inferenct time.\n",
    "\n",
    "### 4.8 More (Keyword only)\n",
    "\n",
    "Classification : \n",
    "- Xception\n",
    "\n",
    "Object Detection :\n",
    "- SPPNet\n",
    "- R-CNN\n",
    "- Fast R-CNN\n",
    "- Faster R-CNN\n",
    "- YOLO v1, v2, v3\n",
    "\n",
    "Semantic segmentation : \n",
    "- Fully Convolutional Networks \n",
    "- U-Net\n",
    "- DeepLab v1, v2, v3\n",
    "- Mask R-CNN\n",
    "\n",
    "Mobile device : \n",
    "- ShuffleNet\n",
    "- SqueezeNet\n",
    "- MobileNet v1, v2\n",
    "\n",
    "## 5. Batch Normalization\n",
    "\n",
    "Paper : [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "\n",
    "### 5.1 Feature Scaling\n",
    "\n",
    "Definition : a method used to standardize the range of independent variables or features of data.\n",
    "\n",
    "Why should we do that ?\n",
    "- Smooth error surface\n",
    "\n",
    "Consider the following figure. Assume $X_1, X_2$ have the same feature importance : \n",
    "\n",
    "![](https://i.imgur.com/YkY8isQ.png)\n",
    "\n",
    "- If numerical range of  a feature is larger than numerical range of another feature, its weight will be more sensitive.\n",
    "    - Learning speed will be different in those weights.\n",
    "    - We should use a small learning rate.\n",
    "        - **Learning speed will be slow.**\n",
    "\n",
    "### 5.2 Internal Covariate Shift\n",
    "\n",
    "#### 5.2.1 Definition\n",
    "\n",
    "In a shallow neural network, we can normalize features to get a smooth error surface. Could we get the same result in deep neural networks ?\n",
    "- No, because **internal covariate shift** will be a problem when the model goes deeper.\n",
    "\n",
    "Covariate shift : \n",
    "- Let $q_{tr}(x)$ is probability density of $x$ in training set\n",
    "- Let $q_{te}(x)$ is probability density of $x$ in test set.\n",
    "- In ideal situation, $q_{tr}(x) = q_{te}(x)$.\n",
    "- In reality, new test samples may be not in the same distribution of training set.\n",
    "    - $q_{tr}(x) \\neq q_{te}(x)$\n",
    "\n",
    "![](https://i.imgur.com/vDUr0Sv.png)\n",
    "\n",
    "Internal covariate shift : the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change.\n",
    "- This slows down the training by requiring lower learning rates and careful parameter initialization.\n",
    "\n",
    "#### 5.2.2 \n",
    "\n",
    "Paper : [How Does Batch Normalization Help Optimization?](https://arxiv.org/pdf/1805.11604.pdf)\n",
    "\n",
    "MIT published at arXiv, Jun 2018.\n",
    "\n",
    "- We find that the widely believed connection between the performance ofBatchNorm and the internal covariate shift is tenuous, at best.\n",
    "- It makes the optimization landscape significantly smoother. This smoothness inducesa more predictive and stable behavior of the gradients, allowing for faster training.\n",
    "\n",
    "### 5.3 Normalization\n",
    "\n",
    "Idea : normalize the internal values at each layer.\n",
    "\n",
    "![](https://i.imgur.com/U3koSRx.png)\n",
    "\n",
    "It is impossible to normalize internal values of full dataset.\n",
    "- Too large\n",
    "- Online generated data\n",
    "\n",
    "Batch normalization : we only normalize the data in a mini-batch.\n",
    "- We expect the distribution of a min-batch data is similar to the distribution of full dataset.\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{m}\\sum_{i=1}^{m} x_i \\\\\n",
    "\\sigma = \\frac{1}{m}\\sum_{i=1}^{m} (x_i - \\mu)^2\\\\\n",
    "\\bar x_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\\\\n",
    "y_i = \\gamma \\bar x_i + \\beta\n",
    "$$\n",
    "\n",
    "- $\\mu$ : mean\n",
    "- $\\sigma$ : standard deviation\n",
    "- $\\gamma, \\beta$ : additional scale and shift. They are trainable variables.\n",
    "\n",
    "Why we need $\\gamma, \\beta$ ?\n",
    "- Simply normalizing each input of a layer may change what the layer can represent.\n",
    "\n",
    "For test, we can not calculate mean and standard deviation of test samples.\n",
    "- Beacuse we may feed only one of few samples into model.\n",
    "- Instead, we calculate moving average of mean and standard deviation during training and use them when testing.\n",
    "\n",
    "## 6. Reference\n",
    "\n",
    "- [Why convolutions always use odd-numbers as filter_size\n",
    "](https://datascience.stackexchange.com/questions/23183/why-convolutions-always-use-odd-numbers-as-filter-size)\n",
    "- [Convolutional Layers: To pad or not to pad?](https://stats.stackexchange.com/questions/246512/convolutional-layers-to-pad-or-not-to-pad)\n",
    "- [ILSVRC 歷屆的深度學習模型](https://chtseng.wordpress.com/2017/11/20/ilsvrc-%E6%AD%B7%E5%B1%86%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B/)\n",
    "- [李宏毅 - Batch Normalization](https://www.youtube.com/watch?v=BZh1ltr5Rkg)\n",
    "- [Wikipideia - Feature Scaling](https://en.wikipedia.org/wiki/Feature_scaling)\n",
    "\n",
    "## 7. A Case Study\n",
    "\n",
    "[Presentation](https://drive.google.com/open?id=1ByQz9htHnm9ueJbsZfydHN8u0ds36nhLLOJ704NDVAI)\n",
    "[Demo](https://merry.ee.ncku.edu.tw/~st9007a/face/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
